{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "images - line by line, cmaera - col by col\n",
    "    Q: is this hardware specific?\n",
    "screen waits 1 frame cycle, camera waits 1 frame cycle \n",
    "    Q: r they the same?\n",
    "\n",
    "\n",
    "two kinds of challenges:\n",
    "    background challenge: one color\n",
    "    lighting challenge: belt of different colr from background color\n",
    "        belt is \"lighting area\"\n",
    "\n",
    "ROI: region that camera is scanning when the screen is displaying the lighting area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "from sklearn.linear_model import LinearRegression as lr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eqn_2(pixel, color1, color2, E):\n",
    "    #INPUTS:\n",
    "        #pixel: a single pixel with all 3 color channels\n",
    "        #color1: background color being shown on screen\n",
    "        #color2: primary color being shown on screen (band)\n",
    "        #E: illuminance for all 3 channels \n",
    "    #confirm that I{c1}/I{c2} = E{c1}/E{c2}\n",
    "    #(where c1 and c2 are the 2 colors being shown on the screen)  \n",
    "\n",
    "    iFraction = pixel[color1]/pixel[color2]\n",
    "    eFraction = E[color1]/E[color2]\n",
    "    epsilon = 0.5\n",
    "    return iFraction- eFraction <= epsilon  \n",
    "\n",
    "\n",
    "def roi(frames, t_begin, u, rows, t_frame, cols, ct_k, ct_frame, fps, color1, color2, E):\n",
    "    # STEP 1: Calculate ROI\n",
    "    # calculate start time to show the lighting area, t_u\n",
    "    t_u = t_begin + (u / rows) * t_frame\n",
    "    # find image - frame at t_u\n",
    "    image = frames[fps * t_u]\n",
    "    # calculate shift, l\n",
    "    l = cols * (t_u - ct_k) / (ct_frame)\n",
    "    \n",
    "\n",
    "    # Apply Eqn 2 on every pixel between response of lighting challenge and background challenge\n",
    "    for r in image.shape[0]:\n",
    "        for c in image.shape[1]:\n",
    "            consistent = eqn_2(image[r][c][:], color1, color2, E)\n",
    "            if not consistent:\n",
    "                print(\"Not consistent!\")\n",
    "                return\n",
    "    \n",
    " \n",
    "    # regression model\n",
    "    #image is 100 columns, ROI is columns 40-65\n",
    "    a,b=10,50\n",
    "    ROI = (a,b)\n",
    "    \n",
    "    imgWidth = image.shape[1]\n",
    "    y_hat = 0\n",
    "    if a < 0.25*imgWidth:\n",
    "        avgCols = None # take average value of columns [a,25]\n",
    "        output = None #lr1.predict(avgCols) #run regression on model 1\n",
    "        y_hat += (0.25*imgWidth-a)*output\n",
    "    if b < 0.5*imgWidth:\n",
    "        #model2: avg. value of columns [25, b]\n",
    "        # run regression on model 2 \n",
    "        avgCols = None\n",
    "        output = None #lr2.predict(avgCols)\n",
    "        y_hat += (b-0.25*imgWidth)*output\n",
    "\n",
    "    if b < 0.75*imgWidth and a > 0.25*imgWidth:\n",
    "        #model 3: avg value of columns [50,b]\n",
    "        avgCols = None\n",
    "        output = None #lr3.predict(avgCols)\n",
    "        y_hat += (b-0.5*imgWidth)*output\n",
    "\n",
    "    if b >=0.75*imgWidth:\n",
    "        #model 4 : avg value of columns [75,b]\n",
    "        avgCols = None\n",
    "        output = None #lr4.predict(avgCols)\n",
    "        y_hat += (b-0.75*imgWidth)*output\n",
    "    \n",
    "    y_hat = y_hat /imgWidth\n",
    "\n",
    "    return y_hat\n",
    "\n",
    "\n",
    "def criteria(frames):\n",
    "    t_begin, u, rows, t_frame, cols, ct_k, ct_frame, fps, color1, color2, E = 1,2,3,4,5,6,7,8,9,10,11\n",
    "    \n",
    "    dVals = []\n",
    "    for frame in frames:\n",
    "        y_hat_i = roi(frames, t_begin, u, rows, t_frame, cols, ct_k, ct_frame, fps, color1, color2, E)\n",
    "\n",
    "        # calc criteria\n",
    "        d = 0.25 #% of screen the band is shown on \n",
    "        imgRows = frame.shape[0] \n",
    "        \n",
    "        d_i = y_hat_i - (u + u+imgRows*0.25)/2\n",
    "        dVals.append(d_i)\n",
    "\n",
    "    mean = np.mean(dVals)\n",
    "    var = np.var(dVals)\n",
    "\n",
    "    threshold = -5\n",
    "    return mean * np.sqrt(var) < np.exp(threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. PASSING EQN2 (ratio of illuminance is met) \n",
    "img = cv2.imread('')\n",
    "background, primary = 0,1 #0=B, 1=G, 2=R\n",
    "illuminance = [255,255,0] #values of illuminance shown on screen\n",
    "\n",
    "for r in range(img.shape[0]):\n",
    "    for c in range(img.shape[1]):\n",
    "        eqn_2(img[c][r][:], background, primary, illuminance)\n",
    "#for each pixel in the img: \n",
    "    #get the relevant color\n",
    "    #input into eqn_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training linear regression models to be used to identify location of band of color\n",
    "#TO DO: need data to train on !! \n",
    "lr1 = lr().fit(x1_train, y1_train)\n",
    "lr2 = lr().fit(x2_train, y2_train)\n",
    "lr3 = lr().fit(x3_train, y3_train)\n",
    "lr4 = lr().fit(x4_train, y4_train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ieee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
